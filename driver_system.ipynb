{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a31513",
   "metadata": {},
   "source": [
    "# AkÄ±llÄ± SÃ¼rÃ¼cÃ¼ Ä°zleme Sistemi \n",
    "\n",
    "Bu proje; kamera gÃ¶rÃ¼ntÃ¼sÃ¼ Ã¼zerinden sÃ¼rÃ¼cÃ¼nÃ¼n **uykulu olma**, **dikkat daÄŸÄ±nÄ±klÄ±ÄŸÄ±**, **telefon kullanÄ±mÄ±**, **gÃ¶z yÃ¶nÃ¼**, ve **sÃ¼rÃ¼cÃ¼ kimliÄŸi uyuÅŸmazlÄ±ÄŸÄ±** gibi durumlarÄ±nÄ± tespit etmeyi amaÃ§lar.\n",
    "\n",
    "Sistem:\n",
    "- MediaPipe FaceMesh ile gÃ¶z aÃ§Ä±klÄ±ÄŸÄ±, iris yÃ¶nÃ¼ ve kafa pozu (yaw/pitch/roll) Ã§Ä±karÄ±r\n",
    "- Haarcascade ile yÃ¼z ROI bulur\n",
    "- Basit kural tabanlÄ± yorgunluk/uyku alarmÄ± Ã¼retir\n",
    "- YOLOv5 + MediaPipe Hands ile telefon kullanÄ±mÄ±nÄ± yakalamaya Ã§alÄ±ÅŸÄ±r\n",
    "- Kritik durumda Web APIâ€™ye acil durum tetikler; Web Ã§alÄ±ÅŸmazsa Telegramâ€™a direkt fallback mesajÄ± yollar\n",
    "- Oturum verilerini JSON olarak `sessions/` klasÃ¶rÃ¼ne kaydeder\n",
    "\n",
    "Notebook yapÄ±sÄ±: Kodlar modÃ¼llere ayrÄ±lmÄ±ÅŸtÄ±r ve en altta `baslat_sistemi_konsoldan()` ile sistem baÅŸlatÄ±lÄ±r.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c3ff7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Ses sistemi (pygame) baslatildi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importlar + Ortam deÄŸiÅŸkenleri (ENV)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import deque\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import threading\n",
    "\n",
    "EMERGENCY_URL = os.getenv(\"EMERGENCY_URL\", \"http://127.0.0.1:5000/api/emergency/trigger\").strip()\n",
    "EMERGENCY_EYES_CLOSED_SECONDS = float(os.getenv(\"EMERGENCY_EYES_CLOSED_SECONDS\", \"10\"))\n",
    "EMERGENCY_COOLDOWN_SECONDS = float(os.getenv(\"EMERGENCY_COOLDOWN_SECONDS\", \"120\"))\n",
    "\n",
    "# --- Telegram \n",
    "TELEGRAM_BOT_TOKEN = os.getenv(\"TELEGRAM_BOT_TOKEN\", \"\").strip()\n",
    "TELEGRAM_CHAT_ID = os.getenv(\"TELEGRAM_CHAT_ID\", \"\").strip()\n",
    "TELEGRAM_DIRECT_FALLBACK_ENABLED = os.getenv(\"TELEGRAM_DIRECT_FALLBACK_ENABLED\", \"0\").strip() == \"1\"\n",
    "\n",
    "# Zorunlu alan kontrolÃ¼\n",
    "if TELEGRAM_DIRECT_FALLBACK_ENABLED:\n",
    "    if not TELEGRAM_BOT_TOKEN:\n",
    "        raise RuntimeError(\"TELEGRAM_DIRECT_FALLBACK_ENABLED=1 ama TELEGRAM_BOT_TOKEN yok (setx yaptÄ±n mÄ±, yeni terminal aÃ§tÄ±n mÄ±?)\")\n",
    "    if not TELEGRAM_CHAT_ID:\n",
    "        raise RuntimeError(\"TELEGRAM_DIRECT_FALLBACK_ENABLED=1 ama TELEGRAM_CHAT_ID yok\")\n",
    "\n",
    "# requests\n",
    "\n",
    "try:\n",
    "    import requests  # type: ignore\n",
    "except Exception as e:\n",
    "    requests = None\n",
    "    print(f\"[UYARI] requests yuklenemedi: {e}. WEB tetikleyici devre disi.\")\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "except ImportError:\n",
    "    mp = None\n",
    "    print(\"[UYARI] mediapipe yÃ¼klÃ¼ deÄŸil (mp=None). FaceMesh/Hands Ã§alÄ±ÅŸmaz.\")\n",
    "try:\n",
    "    import pygame\n",
    "    pygame.mixer.init()\n",
    "    print(\"[OK] Ses sistemi (pygame) baslatildi\")\n",
    "except Exception as e:\n",
    "    pygame = None\n",
    "    print(\"[UYARI] Ses sistemi baslatilamadi:\", e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95d5926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Telegram'a direkt mesaj (fallback)\n",
    "\n",
    "def send_telegram_direct(message: str) -> bool:\n",
    "    \"\"\"\n",
    "    Web Ã§alÄ±ÅŸmÄ±yorsa veya hata veriyorsa, doÄŸrudan Telegram'a mesaj atar.\n",
    "    TELEGRAM_DIRECT_FALLBACK_ENABLED=1 ise aktif olur.\n",
    "    \"\"\"\n",
    "    enabled = os.environ.get(\"TELEGRAM_DIRECT_FALLBACK_ENABLED\", \"0\").strip() == \"1\"\n",
    "    token = os.environ.get(\"TELEGRAM_BOT_TOKEN\", \"\").strip()\n",
    "    chat_id = os.environ.get(\"TELEGRAM_CHAT_ID\", \"\").strip()\n",
    "\n",
    "    if not enabled:\n",
    "        return False\n",
    "    if not token or not chat_id:\n",
    "        print(\"[TELEGRAM] Token veya chat_id eksik.\")\n",
    "        return False\n",
    "    if requests is None:\n",
    "        print(\"[TELEGRAM] requests yok -> mesaj atÄ±lamadÄ±.\")\n",
    "        return False\n",
    "\n",
    "    url = f\"https://api.telegram.org/bot{token}/sendMessage\"\n",
    "    payload = {\"chat_id\": chat_id, \"text\": message}\n",
    "\n",
    "    try:\n",
    "        r = requests.post(url, json=payload, timeout=10)\n",
    "        print(\"[TELEGRAM]\", r.status_code, r.text[:200])\n",
    "        return (200 <= r.status_code < 300)\n",
    "    except Exception as e:\n",
    "        print(\"[TELEGRAM] HATA:\", e)\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "# Web tetikleyici + Telegram fallback  \n",
    "def trigger_emergency_to_web_async(reason: str, seconds: float, session_filename: str = None, extra: dict = None):\n",
    "    \"\"\"\n",
    "    Driver -> Web'e acil durum sinyali gÃ¶nderir (async).\n",
    "    Web tarafÄ± Telegram mesajÄ± gÃ¶nderebilir.\n",
    "    EÄŸer WEB Ã§alÄ±ÅŸmazsa/yanÄ±t vermezse Telegram DIRECT fallback devreye girer.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"reason\": str(reason),\n",
    "        \"seconds\": float(seconds),\n",
    "        \"session_filename\": session_filename,\n",
    "        \"ts\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    }\n",
    "    if extra and isinstance(extra, dict):\n",
    "        payload[\"extra\"] = extra\n",
    "\n",
    "    def _notify_fallback(tag: str, err: str = \"\"):\n",
    "        msg = (\n",
    "            f\"ðŸš¨ ACIL DURUM ({tag})\\n\"\n",
    "            f\"Neden: {payload['reason']}\\n\"\n",
    "            f\"SÃ¼re: {payload['seconds']:.1f}s\\n\"\n",
    "            f\"Zaman: {payload['ts']}\"\n",
    "        )\n",
    "        if payload.get(\"session_filename\"):\n",
    "            msg += f\"\\nSession: {payload['session_filename']}\"\n",
    "        if err:\n",
    "            msg += f\"\\nHata: {err}\"\n",
    "        send_telegram_direct(msg)\n",
    "\n",
    "    def _worker():\n",
    "        if requests is None:\n",
    "            print(\"[EMERGENCY->WEB] requests yok -> web'e gonderilemedi. Telegram fallback denenecek.\")\n",
    "            _notify_fallback(\"WEB_YOK\", \"requests import edilemedi\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            r = requests.post(EMERGENCY_URL, json=payload, timeout=10)\n",
    "            print(\"[EMERGENCY->WEB]\", r.status_code, r.text[:200])\n",
    "\n",
    "            # Web baÅŸarÄ±sÄ±zsa Telegram fallback\n",
    "            if r.status_code < 200 or r.status_code >= 300:\n",
    "                _notify_fallback(f\"WEB_{r.status_code}\", r.text[:200])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"[EMERGENCY->WEB] HATA:\", e)\n",
    "            _notify_fallback(\"WEB_BAGLANTI_HATA\", str(e))\n",
    "\n",
    "    threading.Thread(target=_worker, daemon=True).start()\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56716a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SÃ¼rÃ¼cÃ¼ tanÄ±ma: preprocess + Ã§oklu kare enroll\n",
    "\n",
    "class DriverIdentifier:\n",
    "    def __init__(self, profile_path=\"driver_profile.npy\", sim_threshold=0.82):\n",
    "        self.profile_path = profile_path\n",
    "        self.sim_threshold = sim_threshold\n",
    "        self.ref_vec = None\n",
    "        self._load_profile()\n",
    "\n",
    "    def _load_profile(self):\n",
    "        if os.path.exists(self.profile_path):\n",
    "            try:\n",
    "                data = np.load(self.profile_path, allow_pickle=True)\n",
    "                self.ref_vec = data.item().get(\"ref_vec\") if isinstance(data.item(), dict) else data\n",
    "                print(f\"[OK] Ana sÃ¼rÃ¼cÃ¼ profili yÃ¼klendi: {self.profile_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"[UYARI] Profil okunamadÄ±: {e}\")\n",
    "                self.ref_vec = None\n",
    "\n",
    "    def _save_profile(self):\n",
    "        if self.ref_vec is not None:\n",
    "            np.save(self.profile_path, {\"ref_vec\": self.ref_vec})\n",
    "            print(f\"[OK] Ana sÃ¼rÃ¼cÃ¼ profili kaydedildi: {self.profile_path}\")\n",
    "\n",
    "    def _preprocess_face(self, face_gray: np.ndarray) -> np.ndarray:\n",
    "        fg = face_gray.copy()\n",
    "        h, w = fg.shape[:2]\n",
    "        cx1 = int(w * 0.15)\n",
    "        cx2 = int(w * 0.85)\n",
    "        cy1 = int(h * 0.15)\n",
    "        cy2 = int(h * 0.90)\n",
    "        if cx2 > cx1 and cy2 > cy1:\n",
    "            fg = fg[cy1:cy2, cx1:cx2]\n",
    "\n",
    "        try:\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            fg = clahe.apply(fg)\n",
    "        except Exception:\n",
    "            try:\n",
    "                fg = cv2.equalizeHist(fg)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            fg = cv2.GaussianBlur(fg, (3, 3), 0)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return fg\n",
    "\n",
    "    def _face_to_vec(self, face_gray: np.ndarray):\n",
    "        try:\n",
    "            face_gray = self._preprocess_face(face_gray)\n",
    "            resized = cv2.resize(face_gray, (100, 100))\n",
    "            vec = resized.flatten().astype(\"float32\")\n",
    "            mu = float(vec.mean())\n",
    "            sigma = float(vec.std()) + 1e-6\n",
    "            vec = (vec - mu) / sigma\n",
    "            norm = np.linalg.norm(vec) + 1e-8\n",
    "            return vec / norm\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def enroll_multi(self, face_gray_list):\n",
    "        vecs = []\n",
    "        for fg in face_gray_list:\n",
    "            v = self._face_to_vec(fg)\n",
    "            if v is not None:\n",
    "                vecs.append(v)\n",
    "\n",
    "        if len(vecs) < 8:\n",
    "            return False\n",
    "\n",
    "        ref = np.mean(np.stack(vecs, axis=0), axis=0)\n",
    "        ref = ref / (np.linalg.norm(ref) + 1e-8)\n",
    "        self.ref_vec = ref\n",
    "        self._save_profile()\n",
    "        return True\n",
    "\n",
    "    def similarity(self, face_gray: np.ndarray):\n",
    "        if self.ref_vec is None:\n",
    "            return None\n",
    "        vec = self._face_to_vec(face_gray)\n",
    "        if vec is None:\n",
    "            return None\n",
    "        return float(np.dot(self.ref_vec, vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd6628e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Telefon tespit sistemi (YOLOv5 + MediaPipe Hands)\n",
    "\n",
    "class PhoneDetectionSystem:\n",
    "    def __init__(self, use_yolo=True):\n",
    "        self.use_yolo = use_yolo\n",
    "        self.yolo_model = None\n",
    "\n",
    "        if self.use_yolo:\n",
    "            try:\n",
    "                import torch\n",
    "                print(\"[INFO] YOLOv5 modeli yukleniyor...\")\n",
    "                self.yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "                self.yolo_model.conf = 0.4\n",
    "                self.yolo_model.iou = 0.45\n",
    "                self.yolo_model.eval()\n",
    "                print(\"[OK] YOLOv5 modeli yuklendi\")\n",
    "            except Exception as e:\n",
    "                print(f\"[UYARI] YOLOv5 yuklenemedi: {e}\")\n",
    "                print(\"[INFO] Sadece el-tabanlÄ± tespit kullanilacak\")\n",
    "                self.use_yolo = False\n",
    "\n",
    "        try:\n",
    "            if mp is None:\n",
    "                raise ImportError(\"mediapipe mevcut degil\")\n",
    "            self.mp_hands = mp.solutions.hands\n",
    "            self.hands = self.mp_hands.Hands(\n",
    "                static_image_mode=False,\n",
    "                max_num_hands=2,\n",
    "                min_detection_confidence=0.5,\n",
    "                min_tracking_confidence=0.5\n",
    "            )\n",
    "            print(\"[OK] MediaPipe Hands yuklendi\")\n",
    "        except Exception as e:\n",
    "            print(f\"[HATA] MediaPipe Hands yuklenemedi: {e}\")\n",
    "            self.hands = None\n",
    "\n",
    "        self.phone_detected_frames = 0\n",
    "        self.phone_state = False\n",
    "        self.phone_detection_threshold = 8\n",
    "\n",
    "        self.last_phone_alert_time = 0\n",
    "        self.alert_cooldown = 5.0\n",
    "\n",
    "        self.total_phone_detections = 0\n",
    "        self.phone_usage_duration = 0.0\n",
    "        self.phone_start_time = None\n",
    "\n",
    "        self.detection_history = deque(maxlen=30)\n",
    "\n",
    "    def detect_phone_yolo(self, frame):\n",
    "        if not self.use_yolo or self.yolo_model is None:\n",
    "            return False, []\n",
    "\n",
    "        try:\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.yolo_model(rgb)\n",
    "            detections = results.pandas().xyxy[0]\n",
    "\n",
    "            if 'name' not in detections.columns:\n",
    "                return False, []\n",
    "\n",
    "            phone_detections = detections[detections['name'] == 'cell phone']\n",
    "            if len(phone_detections) > 0:\n",
    "                boxes = []\n",
    "                for _, d in phone_detections.iterrows():\n",
    "                    boxes.append([int(d['xmin']), int(d['ymin']), int(d['xmax']), int(d['ymax']), float(d['confidence'])])\n",
    "                return True, boxes\n",
    "\n",
    "            return False, []\n",
    "        except Exception as e:\n",
    "            print(f\"[HATA] YOLO inference: {e}\")\n",
    "            return False, []\n",
    "\n",
    "    def detect_phone_by_hands(self, frame, face_bbox=None):\n",
    "        if self.hands is None:\n",
    "            return False, []\n",
    "\n",
    "        try:\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = self.hands.process(rgb)\n",
    "            if not results.multi_hand_landmarks:\n",
    "                return False, []\n",
    "\n",
    "            h, w = frame.shape[:2]\n",
    "            suspicious_hands = []\n",
    "\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                wrist = hand_landmarks.landmark[0]\n",
    "                wrist_x, wrist_y = int(wrist.x * w), int(wrist.y * h)\n",
    "\n",
    "                middle_tip = hand_landmarks.landmark[12]\n",
    "                middle_x, middle_y = int(middle_tip.x * w), int(middle_tip.y * h)\n",
    "\n",
    "                pts = [(int(lm.x * w), int(lm.y * h)) for lm in hand_landmarks.landmark]\n",
    "                xs = [p[0] for p in pts]\n",
    "                ys = [p[1] for p in pts]\n",
    "                hand_bbox = [min(xs), min(ys), max(xs), max(ys)]\n",
    "\n",
    "                is_suspicious = False\n",
    "                reasons = []\n",
    "\n",
    "                if face_bbox is not None:\n",
    "                    fx, fy, fw, fh = face_bbox\n",
    "                    face_cy = fy + fh // 2\n",
    "\n",
    "                    if wrist_x > fx + fw + 10 or wrist_x < fx - 10:\n",
    "                        if fy - int(0.3 * fh) < wrist_y < fy + int(1.3 * fh):\n",
    "                            is_suspicious = True\n",
    "                            reasons.append(\"El yuzun yaninda\")\n",
    "\n",
    "                    if abs(wrist_y - face_cy) < fh * 0.8:\n",
    "                        is_suspicious = True\n",
    "                        reasons.append(\"El yuz seviyesinde\")\n",
    "\n",
    "                    if (fx - 100 < wrist_x < fx + fw + 100) and (fy - 100 < wrist_y < fy + fh + 100):\n",
    "                        is_suspicious = True\n",
    "                        reasons.append(\"El yuze cok yakin\")\n",
    "                else:\n",
    "                    if wrist_y < h * 0.6:\n",
    "                        is_suspicious = True\n",
    "                        reasons.append(\"El ust kisimda\")\n",
    "\n",
    "                hand_angle = np.degrees(np.arctan2(middle_y - wrist_y, middle_x - wrist_x))\n",
    "                if -45 < hand_angle < 45 or 135 < abs(hand_angle) < 180:\n",
    "                    is_suspicious = True\n",
    "                    reasons.append(\"Telefon tutus pozisyonu\")\n",
    "\n",
    "                if is_suspicious:\n",
    "                    suspicious_hands.append({\n",
    "                        \"bbox\": hand_bbox,\n",
    "                        \"reason\": \" + \".join(reasons),\n",
    "                        \"wrist\": (wrist_x, wrist_y),\n",
    "                        \"confidence\": 0.7\n",
    "                    })\n",
    "\n",
    "            return (len(suspicious_hands) > 0), suspicious_hands\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[HATA] Hand detection: {e}\")\n",
    "            return False, []\n",
    "\n",
    "    def update(self, frame, face_bbox=None):\n",
    "        yolo_detected, yolo_boxes = self.detect_phone_yolo(frame)\n",
    "        hand_detected, hand_infos = self.detect_phone_by_hands(frame, face_bbox)\n",
    "\n",
    "        detected = yolo_detected or hand_detected\n",
    "        self.detection_history.append(bool(detected))\n",
    "\n",
    "        recent = sum(self.detection_history)\n",
    "        ratio = recent / len(self.detection_history) if len(self.detection_history) else 0.0\n",
    "\n",
    "        if detected:\n",
    "            self.phone_detected_frames += 1\n",
    "        else:\n",
    "            self.phone_detected_frames = max(0, self.phone_detected_frames - 1)\n",
    "\n",
    "        was_using = self.phone_state\n",
    "        self.phone_state = (self.phone_detected_frames >= self.phone_detection_threshold) or (ratio >= 0.5)\n",
    "\n",
    "        now = time.time()\n",
    "        if self.phone_state:\n",
    "            if self.phone_start_time is None:\n",
    "                self.phone_start_time = now\n",
    "                if not was_using:\n",
    "                    self.total_phone_detections += 1\n",
    "        else:\n",
    "            if self.phone_start_time is not None:\n",
    "                self.phone_usage_duration += now - self.phone_start_time\n",
    "                self.phone_start_time = None\n",
    "\n",
    "        should_alert = False\n",
    "        if self.phone_state and (now - self.last_phone_alert_time > self.alert_cooldown):\n",
    "            should_alert = True\n",
    "            self.last_phone_alert_time = now\n",
    "\n",
    "        info = {\n",
    "            \"yolo_detected\": yolo_detected,\n",
    "            \"hand_detected\": hand_detected,\n",
    "            \"yolo_boxes\": yolo_boxes,\n",
    "            \"hand_infos\": hand_infos,\n",
    "            \"confidence\": ratio,\n",
    "            \"frames_detected\": self.phone_detected_frames,\n",
    "            \"total_detections\": self.total_phone_detections,\n",
    "            \"usage_duration\": self.phone_usage_duration\n",
    "        }\n",
    "        return self.phone_state, info, should_alert\n",
    "\n",
    "    def draw_detections(self, frame, detection_info):\n",
    "        for box in detection_info[\"yolo_boxes\"]:\n",
    "            x1, y1, x2, y2, conf = box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
    "            cv2.putText(frame, f\"Telefon {conf:.2f}\", (x1, max(0, y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "        for hi in detection_info[\"hand_infos\"]:\n",
    "            x1, y1, x2, y2 = hi[\"bbox\"]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "            cv2.putText(frame, hi[\"reason\"], (x1, max(0, y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)\n",
    "            wx, wy = hi[\"wrist\"]\n",
    "            cv2.circle(frame, (wx, wy), 5, (255, 0, 255), -1)\n",
    "\n",
    "    def reset_statistics(self):\n",
    "        self.total_phone_detections = 0\n",
    "        self.phone_usage_duration = 0.0\n",
    "        self.phone_start_time = None\n",
    "        self.phone_detected_frames = 0\n",
    "        self.phone_state = False\n",
    "        self.detection_history.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83a3cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sesli uyarÄ± sistemi \n",
    "\n",
    "class AudioAlertSystem:\n",
    "    def __init__(self):\n",
    "        self.enabled = False\n",
    "        self.last_alert_time = 0.0\n",
    "        self.alert_cooldown = 3.0\n",
    "\n",
    "        self.drowsy_sound = None\n",
    "        self.distraction_sound = None\n",
    "        self.warning_sound = None\n",
    "\n",
    "        if pygame is None:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.enabled = True\n",
    "            self._create_sounds()\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] pygame ses sistemi baslatilamadi: {e}. Sesli uyarilar devre disi.\")\n",
    "            self.enabled = False\n",
    "\n",
    "    def _create_sounds(self):\n",
    "        if not self.enabled or pygame is None:\n",
    "            return\n",
    "\n",
    "        sample_rate = 22050\n",
    "\n",
    "        def _tone(freq: float, duration: float):\n",
    "            samples = int(sample_rate * duration)\n",
    "            wave = np.sin(2 * np.pi * freq * np.linspace(0, duration, samples))\n",
    "            wave = (wave * 32767).astype(np.int16)\n",
    "            stereo = np.column_stack((wave, wave))\n",
    "            return pygame.sndarray.make_sound(stereo)\n",
    "\n",
    "        self.drowsy_sound = _tone(880, 0.5)\n",
    "        self.distraction_sound = _tone(440, 0.5)\n",
    "        self.warning_sound = _tone(220, 0.3)\n",
    "\n",
    "    def play_alert(self, alert_type=\"drowsy\"):\n",
    "        if not self.enabled:\n",
    "            return\n",
    "\n",
    "        now = time.time()\n",
    "        if now - self.last_alert_time < self.alert_cooldown:\n",
    "            return\n",
    "\n",
    "        snd = None\n",
    "        if alert_type == \"drowsy\":\n",
    "            snd = self.drowsy_sound\n",
    "        elif alert_type == \"distraction\":\n",
    "            snd = self.distraction_sound\n",
    "        elif alert_type == \"warning\":\n",
    "            snd = self.warning_sound\n",
    "\n",
    "        if snd is not None:\n",
    "            try:\n",
    "                snd.play()\n",
    "            except Exception as e:\n",
    "                print(f\"[UYARI] Ses calinamadi ({alert_type}): {e}. Ses devre disi.\")\n",
    "                self.enabled = False\n",
    "\n",
    "        self.last_alert_time = now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d40a86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri kayÄ±t sistemi \n",
    "\n",
    "class DataLogger:\n",
    "    def __init__(self, log_file=None):\n",
    "        os.makedirs(\"sessions\", exist_ok=True)\n",
    "\n",
    "        if log_file is None:\n",
    "            ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            log_file = os.path.join(\"sessions\", f\"surucu_oturumu_{ts}.json\")\n",
    "        else:\n",
    "            if not os.path.isabs(log_file) and os.path.dirname(log_file) == \"\":\n",
    "                log_file = os.path.join(\"sessions\", log_file)\n",
    "\n",
    "        self.log_file = log_file\n",
    "        self.session_start = datetime.now()\n",
    "        self.session_data = {\n",
    "            \"start_time\": self.session_start.isoformat(),\n",
    "            \"end_time\": None,\n",
    "            \"records\": [],\n",
    "            \"statistics\": {}\n",
    "        }\n",
    "        self.record_interval = 1.0\n",
    "        self.last_record_time = 0\n",
    "\n",
    "    def add_record(self, emotion_idx, emotion_labels, probs, eye_score,\n",
    "                   drowsy_state, head_yaw, distracted, phone_using,\n",
    "                   driver_similarity, driver_mismatch, mouth_open_score=None,\n",
    "                   eye_gaze_distracted=False, eye_gaze_direction=\"center\"):\n",
    "        now = time.time()\n",
    "        if now - self.last_record_time < self.record_interval:\n",
    "            return\n",
    "\n",
    "        record = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"emotion\": emotion_labels[emotion_idx],\n",
    "            \"emotion_probs\": {\n",
    "                \"normal\": float(probs[0]),\n",
    "                \"tired\": float(probs[1])\n",
    "            },\n",
    "            \"eye_openness\": float(eye_score),\n",
    "            \"drowsy\": (drowsy_state == \"Drowsy\"),\n",
    "            \"head_yaw\": float(head_yaw),\n",
    "            \"distracted\": bool(distracted),\n",
    "            \"phone_using\": bool(phone_using),\n",
    "            \"driver_similarity\": None if driver_similarity is None else float(driver_similarity),\n",
    "            \"driver_mismatch\": bool(driver_mismatch),\n",
    "            \"eye_gaze_distracted\": bool(eye_gaze_distracted),\n",
    "            \"eye_gaze_direction\": str(eye_gaze_direction)\n",
    "        }\n",
    "        if mouth_open_score is not None:\n",
    "            record[\"mouth_open_score\"] = float(mouth_open_score)\n",
    "\n",
    "        self.session_data[\"records\"].append(record)\n",
    "        self.last_record_time = now\n",
    "\n",
    "    def save_session(self):\n",
    "        self.session_data[\"end_time\"] = datetime.now().isoformat()\n",
    "\n",
    "        if self.session_data[\"records\"]:\n",
    "            rec = self.session_data[\"records\"]\n",
    "            self.session_data[\"statistics\"] = {\n",
    "                \"total_duration_seconds\": len(rec),\n",
    "                \"average_eye_openness\": float(np.mean([r[\"eye_openness\"] for r in rec])),\n",
    "                \"drowsy_percentage\": float(sum([r[\"drowsy\"] for r in rec]) / len(rec) * 100),\n",
    "                \"distracted_percentage\": float(sum([r[\"distracted\"] for r in rec]) / len(rec) * 100),\n",
    "                \"phone_using_percentage\": float(sum([r[\"phone_using\"] for r in rec]) / len(rec) * 100),\n",
    "                \"driver_mismatch_percentage\": float(sum([r[\"driver_mismatch\"] for r in rec]) / len(rec) * 100),\n",
    "                \"eye_gaze_distracted_percentage\": float(sum([r.get(\"eye_gaze_distracted\", False) for r in rec]) / len(rec) * 100),\n",
    "                \"emotion_distribution\": {\n",
    "                    \"normal\": float(sum([1 for r in rec if r[\"emotion\"] == \"Normal\"]) / len(rec) * 100),\n",
    "                    \"tired\": float(sum([1 for r in rec if r[\"emotion\"] == \"Yorgun\"]) / len(rec) * 100),\n",
    "                }\n",
    "            }\n",
    "\n",
    "        with open(self.log_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.session_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"\\n[LOG] Oturum kaydedildi: {self.log_file}\")\n",
    "        print(f\"[LOG] SÃ¼re: {len(self.session_data['records'])} saniye\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d1a8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor (duygu Ã¶zellikleri) \n",
    "class EmotionFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.roi_coordinates = {\n",
    "            'left_eye': (10, 15, 18, 10),\n",
    "            'right_eye': (10, 30, 18, 10),\n",
    "            'left_eyebrow': (5, 12, 8, 15),\n",
    "            'right_eyebrow': (5, 28, 8, 15),\n",
    "            'mouth': (32, 18, 12, 20),\n",
    "        }\n",
    "\n",
    "    def extract_features(self, image: np.ndarray) -> np.ndarray:\n",
    "        if image.max() <= 1.0:\n",
    "            img = (image * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img = image.astype(np.uint8)\n",
    "\n",
    "        features = []\n",
    "        features.extend(self._extract_eye_features(img))\n",
    "        features.extend(self._extract_eyebrow_features(img))\n",
    "        features.extend(self._extract_mouth_features(img))\n",
    "        features.extend(self._extract_global_features(img))\n",
    "        return np.array(features, dtype=np.float32)\n",
    "\n",
    "    def _extract_eye_features(self, img: np.ndarray):\n",
    "        features = []\n",
    "        for eye_name in ['left_eye', 'right_eye']:\n",
    "            y, x, h, w = self.roi_coordinates[eye_name]\n",
    "            eye_roi = img[y:y+h, x:x+w]\n",
    "            if eye_roi.size == 0:\n",
    "                features.extend([0.0, 0.0, 0.0, 0.0])\n",
    "                continue\n",
    "\n",
    "            eye_thresh = cv2.adaptiveThreshold(\n",
    "                eye_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                cv2.THRESH_BINARY_INV, 11, 2\n",
    "            )\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "            eye_morph = cv2.morphologyEx(eye_thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "            features.append(np.sum(eye_morph == 255) / eye_morph.size)\n",
    "            features.append(np.mean(eye_roi) / 255.0)\n",
    "            features.append(np.std(eye_roi) / 255.0)\n",
    "\n",
    "            contours, _ = cv2.findContours(eye_morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            features.append(len(contours) / 10.0)\n",
    "        return features\n",
    "\n",
    "    def _extract_eyebrow_features(self, img: np.ndarray):\n",
    "        features = []\n",
    "        for brow_name in ['left_eyebrow', 'right_eyebrow']:\n",
    "            y, x, h, w = self.roi_coordinates[brow_name]\n",
    "            brow_roi = img[y:y+h, x:x+w]\n",
    "            if brow_roi.size == 0:\n",
    "                features.extend([0.0, 0.0, 0.0])\n",
    "                continue\n",
    "\n",
    "            _, brow_thresh = cv2.threshold(brow_roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            features.append(np.sum(brow_thresh == 255) / brow_thresh.size)\n",
    "\n",
    "            upper_half = np.mean(brow_roi[:h//2, :])\n",
    "            lower_half = np.mean(brow_roi[h//2:, :])\n",
    "            features.append((upper_half - lower_half) / 255.0)\n",
    "\n",
    "            sobelx = cv2.Sobel(brow_roi, cv2.CV_64F, 1, 0, ksize=3)\n",
    "            sobely = cv2.Sobel(brow_roi, cv2.CV_64F, 0, 1, ksize=3)\n",
    "            mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "            features.append(np.mean(mag) / 255.0)\n",
    "        return features\n",
    "\n",
    "    def _extract_mouth_features(self, img: np.ndarray):\n",
    "        features = []\n",
    "        y, x, h, w = self.roi_coordinates['mouth']\n",
    "        mouth_roi = img[y:y+h, x:x+w]\n",
    "        if mouth_roi.size == 0:\n",
    "            features.extend([0.0] * 6)\n",
    "            return features\n",
    "\n",
    "        mouth_thresh = cv2.adaptiveThreshold(\n",
    "            mouth_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV, 11, 2\n",
    "        )\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 3))\n",
    "        mouth_closed = cv2.morphologyEx(mouth_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        vertical_profile = np.sum(mouth_closed, axis=1)\n",
    "        features.append(np.max(vertical_profile) / (w * 255))\n",
    "\n",
    "        horizontal_profile = np.sum(mouth_closed, axis=0)\n",
    "        features.append(np.sum(horizontal_profile > 0) / w)\n",
    "\n",
    "        features.append(np.mean(mouth_roi[:h//2, :]) / 255.0)\n",
    "        features.append(np.mean(mouth_roi[h//2:, :]) / 255.0)\n",
    "\n",
    "        left_half = np.mean(mouth_roi[:, :w//2])\n",
    "        right_half = np.mean(mouth_roi[:, w//2:])\n",
    "        features.append(abs(left_half - right_half) / 255.0)\n",
    "\n",
    "        contours, _ = cv2.findContours(mouth_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        features.append(len(contours) / 5.0)\n",
    "        return features\n",
    "\n",
    "    def _extract_global_features(self, img: np.ndarray):\n",
    "        features = []\n",
    "        features.append(np.mean(img) / 255.0)\n",
    "        features.append(np.std(img) / 255.0)\n",
    "\n",
    "        hist = cv2.calcHist([img], [0], None, [16], [0, 256]).flatten()\n",
    "        hist_sum = hist.sum() if hist.sum() > 0 else 1.0\n",
    "        hist = hist / hist_sum\n",
    "\n",
    "        features.append(np.mean(hist[:8]))\n",
    "        features.append(np.mean(hist[8:]))\n",
    "\n",
    "        left_half = img[:, :img.shape[1]//2]\n",
    "        right_half = cv2.flip(img[:, img.shape[1]//2:], 1)\n",
    "        min_width = min(left_half.shape[1], right_half.shape[1])\n",
    "        if min_width > 0:\n",
    "            diff = np.abs(left_half[:, :min_width] - right_half[:, :min_width])\n",
    "            features.append(np.mean(diff) / 255.0)\n",
    "        else:\n",
    "            features.append(0.0)\n",
    "\n",
    "        gabor_kernel = cv2.getGaborKernel((5, 5), 3, 0, 10, 0.5, 0)\n",
    "        gabor_filtered = cv2.filter2D(img, cv2.CV_64F, gabor_kernel)\n",
    "        features.append(np.mean(np.abs(gabor_filtered)) / 255.0)\n",
    "        return features\n",
    "\n",
    "\n",
    "class SimpleNNWrapper:\n",
    "    def __init__(self, model_path: str):\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        self.weights = model_data['weights']\n",
    "        self.biases = model_data['biases']\n",
    "        self.activation_type = model_data['activation_type']\n",
    "\n",
    "    def _activation(self, z):\n",
    "        if self.activation_type == 'relu':\n",
    "            return np.maximum(0, z)\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "\n",
    "    def _softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        a = X\n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            z = np.dot(a, w) + b\n",
    "            if i == len(self.weights) - 1:\n",
    "                a = self._softmax(z)\n",
    "            else:\n",
    "                a = self._activation(z)\n",
    "        return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05d9466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GÃ¶z yÃ¶nÃ¼ (iris tracking) + gÃ¶z aÃ§Ä±klÄ±ÄŸÄ± + kafa pozu\n",
    "\n",
    "class EyeGazeDetector:\n",
    "    def __init__(self, gaze_threshold=0.15, hold_seconds=2.5, release_seconds=0.6):\n",
    "        self.gaze_threshold = float(gaze_threshold)\n",
    "        self.hold_seconds = float(hold_seconds)\n",
    "        self.release_seconds = float(release_seconds)\n",
    "\n",
    "        self._left_gaze_since = None\n",
    "        self._right_gaze_since = None\n",
    "        self._center_since = None\n",
    "        self.state = False\n",
    "        self.last_direction = \"center\"\n",
    "\n",
    "    def _get_eye_gaze_direction(self, face_landmarks):\n",
    "        try:\n",
    "            left_iris = face_landmarks[468]\n",
    "            left_corner_left = face_landmarks[33]\n",
    "            left_corner_right = face_landmarks[133]\n",
    "\n",
    "            right_iris = face_landmarks[473]\n",
    "            right_corner_left = face_landmarks[362]\n",
    "            right_corner_right = face_landmarks[263]\n",
    "\n",
    "            left_eye_width = abs(left_corner_right.x - left_corner_left.x)\n",
    "            left_iris_offset = (left_iris.x - left_corner_left.x) / (left_eye_width + 1e-6)\n",
    "\n",
    "            right_eye_width = abs(right_corner_right.x - right_corner_left.x)\n",
    "            right_iris_offset = (right_iris.x - right_corner_left.x) / (right_eye_width + 1e-6)\n",
    "\n",
    "            avg_offset = (left_iris_offset + right_iris_offset) / 2.0\n",
    "\n",
    "            if avg_offset < (0.5 - self.gaze_threshold):\n",
    "                return \"left\", avg_offset\n",
    "            elif avg_offset > (0.5 + self.gaze_threshold):\n",
    "                return \"right\", avg_offset\n",
    "            else:\n",
    "                return \"center\", avg_offset\n",
    "\n",
    "        except Exception:\n",
    "            return \"center\", 0.5\n",
    "\n",
    "    def update(self, face_landmarks):\n",
    "        direction, offset = self._get_eye_gaze_direction(face_landmarks)\n",
    "        self.last_direction = direction\n",
    "        now = time.time()\n",
    "\n",
    "        if direction in (\"left\", \"right\"):\n",
    "            self._center_since = None\n",
    "\n",
    "            if direction == \"left\":\n",
    "                if self._left_gaze_since is None:\n",
    "                    self._left_gaze_since = now\n",
    "                    self._right_gaze_since = None\n",
    "                if (now - self._left_gaze_since) >= self.hold_seconds:\n",
    "                    self.state = True\n",
    "\n",
    "            if direction == \"right\":\n",
    "                if self._right_gaze_since is None:\n",
    "                    self._right_gaze_since = now\n",
    "                    self._left_gaze_since = None\n",
    "                if (now - self._right_gaze_since) >= self.hold_seconds:\n",
    "                    self.state = True\n",
    "\n",
    "        else:\n",
    "            self._left_gaze_since = None\n",
    "            self._right_gaze_since = None\n",
    "\n",
    "            if self._center_since is None:\n",
    "                self._center_since = now\n",
    "\n",
    "            if self.state and (now - self._center_since) >= self.release_seconds:\n",
    "                self.state = False\n",
    "\n",
    "        return self.state, direction, offset\n",
    "\n",
    "\n",
    "def _lm_to_np(landmarks, idx):\n",
    "    lm = landmarks[idx]\n",
    "    return np.array([lm.x, lm.y], dtype=np.float32)\n",
    "\n",
    "def compute_eye_openness(face_landmarks):\n",
    "    left_corner_outer = _lm_to_np(face_landmarks, 33)\n",
    "    left_corner_inner = _lm_to_np(face_landmarks, 133)\n",
    "    left_upper = (_lm_to_np(face_landmarks, 159) + _lm_to_np(face_landmarks, 160)) / 2.0\n",
    "    left_lower = (_lm_to_np(face_landmarks, 145) + _lm_to_np(face_landmarks, 144)) / 2.0\n",
    "\n",
    "    right_corner_outer = _lm_to_np(face_landmarks, 263)\n",
    "    right_corner_inner = _lm_to_np(face_landmarks, 362)\n",
    "    right_upper = (_lm_to_np(face_landmarks, 386) + _lm_to_np(face_landmarks, 387)) / 2.0\n",
    "    right_lower = (_lm_to_np(face_landmarks, 374) + _lm_to_np(face_landmarks, 373)) / 2.0\n",
    "\n",
    "    left_vert = np.linalg.norm(left_upper - left_lower)\n",
    "    left_horiz = np.linalg.norm(left_corner_outer - left_corner_inner) + 1e-6\n",
    "    left_ratio = left_vert / left_horiz\n",
    "\n",
    "    right_vert = np.linalg.norm(right_upper - right_lower)\n",
    "    right_horiz = np.linalg.norm(right_corner_outer - right_corner_inner) + 1e-6\n",
    "    right_ratio = right_vert / right_horiz\n",
    "\n",
    "    eye_ratio = (left_ratio + right_ratio) / 2.0\n",
    "\n",
    "    min_ratio = 0.15\n",
    "    max_ratio = 0.35\n",
    "    norm = (eye_ratio - min_ratio) / (max_ratio - min_ratio)\n",
    "    eye_open_score = float(np.clip(norm, 0.0, 1.0))\n",
    "    return eye_open_score, eye_ratio\n",
    "\n",
    "def compute_head_pose(face_landmarks, img_width, img_height):\n",
    "    model_points = np.array([\n",
    "        (0.0, 0.0, 0.0),\n",
    "        (0.0, -330.0, -65.0),\n",
    "        (-225.0, 170.0, -135.0),\n",
    "        (225.0, 170.0, -135.0),\n",
    "        (-150.0, -150.0, -125.0),\n",
    "        (150.0, -150.0, -125.0)\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "    image_points = np.array([\n",
    "        (face_landmarks[1].x * img_width, face_landmarks[1].y * img_height),\n",
    "        (face_landmarks[152].x * img_width, face_landmarks[152].y * img_height),\n",
    "        (face_landmarks[33].x * img_width, face_landmarks[33].y * img_height),\n",
    "        (face_landmarks[263].x * img_width, face_landmarks[263].y * img_height),\n",
    "        (face_landmarks[61].x * img_width, face_landmarks[61].y * img_height),\n",
    "        (face_landmarks[291].x * img_width, face_landmarks[291].y * img_height)\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "    focal_length = img_width\n",
    "    center = (img_width / 2, img_height / 2)\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "    dist_coeffs = np.zeros((4, 1))\n",
    "\n",
    "    success, rvec, tvec = cv2.solvePnP(\n",
    "        model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE\n",
    "    )\n",
    "    if not success:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    rmat, _ = cv2.Rodrigues(rvec)\n",
    "    pose_mat = cv2.hconcat((rmat, tvec))\n",
    "    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_mat)\n",
    "\n",
    "    pitch = euler_angles[0][0]\n",
    "    yaw = euler_angles[1][0]\n",
    "    roll = euler_angles[2][0]\n",
    "    return yaw, pitch, roll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53736d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uyku (gÃ¶z kapalÄ±) + dikkat daÄŸÄ±nÄ±klÄ±ÄŸÄ± (yaw) state makinesi\n",
    "\n",
    "class DriverSafetySystem:\n",
    "    def __init__(self, eye_open_threshold=0.30, drowsy_frames_threshold=18, smoothing_window=8):\n",
    "        self.eye_open_threshold = eye_open_threshold\n",
    "        self.drowsy_frames_threshold = drowsy_frames_threshold\n",
    "        self.eye_score_buffer = deque(maxlen=smoothing_window)\n",
    "        self.closed_eye_frames = 0\n",
    "        self.state = \"Alert\"\n",
    "\n",
    "    def update(self, raw_eye_open_score):\n",
    "        self.eye_score_buffer.append(raw_eye_open_score)\n",
    "        smooth_eye_score = float(np.mean(self.eye_score_buffer))\n",
    "\n",
    "        eye_is_closed = smooth_eye_score < self.eye_open_threshold\n",
    "        if eye_is_closed:\n",
    "            self.closed_eye_frames += 1\n",
    "        else:\n",
    "            self.closed_eye_frames = 0\n",
    "\n",
    "        self.state = \"Drowsy\" if self.closed_eye_frames >= self.drowsy_frames_threshold else \"Alert\"\n",
    "        return smooth_eye_score, self.closed_eye_frames, self.state\n",
    "\n",
    "\n",
    "class DistractionDetector:\n",
    "    def __init__(self, yaw_threshold=25, hold_seconds=2.5, release_seconds=0.6):\n",
    "        self.yaw_threshold = float(yaw_threshold)\n",
    "        self.hold_seconds = float(hold_seconds)\n",
    "        self.release_seconds = float(release_seconds)\n",
    "\n",
    "        self._above_since = None\n",
    "        self._below_since = None\n",
    "        self.state = False\n",
    "\n",
    "    def update(self, yaw_angle):\n",
    "        now = time.time()\n",
    "        yaw_abs = abs(float(yaw_angle))\n",
    "\n",
    "        if yaw_abs > self.yaw_threshold:\n",
    "            self._below_since = None\n",
    "            if self._above_since is None:\n",
    "                self._above_since = now\n",
    "            if (now - self._above_since) >= self.hold_seconds:\n",
    "                self.state = True\n",
    "        else:\n",
    "            self._above_since = None\n",
    "            if self._below_since is None:\n",
    "                self._below_since = now\n",
    "            if self.state and (now - self._below_since) >= self.release_seconds:\n",
    "                self.state = False\n",
    "\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fc1049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ana sistem: FullDriverMonitoringSystem\n",
    "\n",
    "class FullDriverMonitoringSystem:\n",
    "    def __init__(self, model_path='emotion_model.pkl', norm_path='normalization_params.npz'):\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Tam Surucu Izleme Sistemi\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        self.model = None\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        try:\n",
    "            self.model = SimpleNNWrapper(model_path)\n",
    "            norm_data = np.load(norm_path)\n",
    "            self.mean = norm_data['mean']\n",
    "            self.std = norm_data['std']\n",
    "            print(\"[OK] Duygu modeli yuklendi\")\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] Model yuklenemedi: {e}, sadece kural tabani kullanilacak\")\n",
    "\n",
    "        self.emotion_labels = ['Normal', 'Yorgun']\n",
    "        self.num_emotions = len(self.emotion_labels)\n",
    "\n",
    "        cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        self.face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "        self.feature_extractor = EmotionFeatureExtractor()\n",
    "\n",
    "        self.last_emotion_idx = 0\n",
    "        self.last_probabilities = np.array([0.95, 0.05], dtype=float)\n",
    "        self.last_confidence = 0.95\n",
    "        self.prob_history = deque(maxlen=10)\n",
    "\n",
    "        self.fps_buffer = deque(maxlen=30)\n",
    "\n",
    "        if mp is None:\n",
    "            raise ImportError('mediapipe mevcut degil: FaceMesh baslatilamadi.')\n",
    "        mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.face_mesh = mp_face_mesh.FaceMesh(\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5,\n",
    "        )\n",
    "\n",
    "        self.safety_system = DriverSafetySystem(\n",
    "            eye_open_threshold=0.20,\n",
    "            drowsy_frames_threshold=25,\n",
    "            smoothing_window=10\n",
    "        )\n",
    "\n",
    "        self.distraction_detector = DistractionDetector(\n",
    "            yaw_threshold=25,\n",
    "            hold_seconds=2.5,\n",
    "            release_seconds=0.6\n",
    "        )\n",
    "\n",
    "        self.eye_gaze_detector = EyeGazeDetector(\n",
    "            gaze_threshold=0.15,\n",
    "            hold_seconds=2.5,\n",
    "            release_seconds=0.6\n",
    "        )\n",
    "        print(\"[OK] Goz yonu tespit sistemi hazir\")\n",
    "\n",
    "        self.phone_detector = PhoneDetectionSystem(use_yolo=True)\n",
    "        print(\"[OK] Telefon tespit sistemi hazir\")\n",
    "\n",
    "        try:\n",
    "            self.audio_system = AudioAlertSystem()\n",
    "            print(\"[OK] Ses sistemi baslatildi\")\n",
    "        except Exception as e:\n",
    "            print(f\"[UYARI] Ses sistemi baslatilamadi: {e}\")\n",
    "            self.audio_system = None\n",
    "\n",
    "        self.data_logger = DataLogger()\n",
    "        print(\"[OK] Veri kayit sistemi hazir\")\n",
    "\n",
    "        self.eye_score_history = deque(maxlen=150)\n",
    "\n",
    "        self.driver_id = DriverIdentifier(profile_path=\"driver_profile.npy\", sim_threshold=0.70)\n",
    "        self.main_driver_enabled = (self.driver_id.ref_vec is not None)\n",
    "\n",
    "        self.sim_history = deque(maxlen=60)\n",
    "        self.sim_low_threshold = self.driver_id.sim_threshold\n",
    "        self.sim_high_threshold = min(0.985, self.sim_low_threshold + 0.10)\n",
    "\n",
    "        self.driver_mismatch_frames = 0\n",
    "        self.driver_mismatch_threshold_frames = 60\n",
    "        self.driver_mismatch_state = False\n",
    "\n",
    "        self.driver_alert_cooldown = 10.0\n",
    "        self.last_driver_alert_time = 0.0\n",
    "        self.last_driver_similarity = None\n",
    "\n",
    "        self.enroll_mode = False\n",
    "        self.enroll_samples = []\n",
    "        self.enroll_start_time = 0.0\n",
    "        self.enroll_duration = 4.0\n",
    "        self.enroll_blur_threshold = 70\n",
    "        self.match_blur_threshold = 50\n",
    "\n",
    "        self.frame_idx = 0\n",
    "        self.emotion_every_n_frames = 2\n",
    "\n",
    "        self.last_mouth_open_score = 0.0\n",
    "        self.debug_scores = True\n",
    "\n",
    "        self._eyes_closed_since = None\n",
    "        self._last_emergency_sent = 0.0\n",
    "        self._emergency_cooldown = EMERGENCY_COOLDOWN_SECONDS\n",
    "\n",
    "    def _rule_based_emotion(self, smooth_eye_score, drowsy_state, head_down_score, mouth_open_score):\n",
    "        mouth_yawn_threshold = 0.50\n",
    "        head_down_thr = 0.12\n",
    "        eye_closed_thr = 0.20\n",
    "\n",
    "        mouth_open = float(mouth_open_score)\n",
    "        head_down = (float(head_down_score) > head_down_thr)\n",
    "        eyes_closed = (float(smooth_eye_score) < eye_closed_thr)\n",
    "\n",
    "        if drowsy_state == \"Drowsy\":\n",
    "            idx = 1\n",
    "            probs = np.array([0.10, 0.90], dtype=float)\n",
    "            conf = 0.90\n",
    "            return idx, probs, conf\n",
    "\n",
    "        yorgun_signals = 0\n",
    "        if eyes_closed:\n",
    "            yorgun_signals += 1\n",
    "        if head_down:\n",
    "            yorgun_signals += 1\n",
    "        if mouth_open > mouth_yawn_threshold:\n",
    "            yorgun_signals += 1\n",
    "\n",
    "        if yorgun_signals >= 2:\n",
    "            idx = 1\n",
    "            probs = np.array([0.20, 0.80], dtype=float)\n",
    "            conf = 0.80\n",
    "            return idx, probs, conf\n",
    "\n",
    "        idx = 0\n",
    "        probs = np.array([0.95, 0.05], dtype=float)\n",
    "        conf = 0.95\n",
    "        return idx, probs, conf\n",
    "\n",
    "    def predict_emotion_from_features(self, features: np.ndarray,\n",
    "                                     smooth_eye_score, drowsy_state,\n",
    "                                     head_down_score, mouth_open_score):\n",
    "        rb_idx, rb_probs, rb_conf = self._rule_based_emotion(\n",
    "            smooth_eye_score, drowsy_state, head_down_score, mouth_open_score\n",
    "        )\n",
    "\n",
    "        if self.model is None or self.mean is None or self.std is None:\n",
    "            return rb_idx, rb_probs, rb_conf\n",
    "\n",
    "        try:\n",
    "            features_norm = (features - self.mean) / (self.std + 1e-8)\n",
    "        except Exception:\n",
    "            features_norm = features\n",
    "\n",
    "        try:\n",
    "            _ = self.model.predict_proba(features_norm.reshape(1, -1))[0]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        return rb_idx, rb_probs, rb_conf\n",
    "\n",
    "    def draw_eye_trend_graph(self, frame):\n",
    "        if len(self.eye_score_history) < 2:\n",
    "            return\n",
    "\n",
    "        h, w = frame.shape[:2]\n",
    "        graph_h = 80\n",
    "        graph_w = 200\n",
    "        graph_x = w - graph_w - 20\n",
    "        graph_y = 20\n",
    "\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (graph_x-10, graph_y-10), (graph_x+graph_w+10, graph_y+graph_h+10), (40, 40, 40), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "\n",
    "        cv2.putText(frame, \"Goz Aciklik Trend\", (graph_x, graph_y-15),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "        pts = list(self.eye_score_history)\n",
    "        step = graph_w / max(len(pts) - 1, 1)\n",
    "\n",
    "        for i in range(len(pts) - 1):\n",
    "            x1 = int(graph_x + i * step)\n",
    "            y1 = int(graph_y + graph_h - (pts[i] * graph_h))\n",
    "            x2 = int(graph_x + (i + 1) * step)\n",
    "            y2 = int(graph_y + graph_h - (pts[i + 1] * graph_h))\n",
    "            color_val = int(pts[i] * 255)\n",
    "            color = (0, color_val, 255 - color_val)\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        threshold_y = int(graph_y + graph_h - (0.30 * graph_h))\n",
    "        cv2.line(frame, (graph_x, threshold_y), (graph_x + graph_w, threshold_y), (0, 0, 255), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1048efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FullDriverMonitoringSystem devam: draw_overlay + run\n",
    "\n",
    "\n",
    "def _fullsystem_draw_overlay_and_run_patch():\n",
    "    # Bu fonksiyon sadece notebook dÃ¼zeni iÃ§in bir \"patch\" deÄŸil.\n",
    "    # AÅŸaÄŸÄ±da FullDriverMonitoringSystem sÄ±nÄ±fÄ±na metodlarÄ± ekleyeceÄŸiz.\n",
    "    pass\n",
    "\n",
    "\n",
    "def _draw_overlay(self, frame, emotion_idx, probs, confidence,\n",
    "                  smooth_eye_score, closed_eye_frames, drowsy_state,\n",
    "                  fps, yaw_angle, distraction_state, phone_state,\n",
    "                  sim_value, main_driver_enabled, mismatch_state,\n",
    "                  enroll_mode, eye_gaze_distracted, eye_gaze_direction):\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    overlay = frame.copy()\n",
    "    left_panel_w = 500 if self.debug_scores else 460\n",
    "    left_panel_h = 370 if self.debug_scores else 340\n",
    "    cv2.rectangle(overlay, (15, 15), (15 + left_panel_w, 15 + left_panel_h), (25, 25, 25), -1)\n",
    "    cv2.addWeighted(overlay, 0.78, frame, 0.22, 0, frame)\n",
    "\n",
    "    cv2.putText(frame, \"AKILLI SURUCU IZLEME\", (25, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.65, (245, 245, 245), 2)\n",
    "\n",
    "    label = self.emotion_labels[emotion_idx]\n",
    "    color = (40, 220, 120) if emotion_idx == 0 else (0, 170, 255)\n",
    "\n",
    "    y = 70\n",
    "    cv2.putText(frame, f\"Duygu: {label}\", (25, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.85, color, 2)\n",
    "    cv2.putText(frame, f\"Guven: {confidence*100:.0f}%\", (25, y + 28),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.55, (220, 220, 220), 1)\n",
    "\n",
    "    y += 60\n",
    "    cv2.putText(frame, f\"Goz aciklik skoru: {smooth_eye_score:.2f}\", (25, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.55, (210, 210, 80), 1)\n",
    "    cv2.putText(frame, f\"Art arda kapali kare: {closed_eye_frames}\", (25, y + 22),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (190, 190, 190), 1)\n",
    "\n",
    "    y += 55\n",
    "    badge_color = (0, 0, 255) if drowsy_state == \"Drowsy\" else (0, 180, 70)\n",
    "    badge_text = \"UYKULU\" if drowsy_state == \"Drowsy\" else \"DIKKATLI\"\n",
    "    cv2.rectangle(frame, (25, y - 18), (25 + 120, y + 10), badge_color, -1)\n",
    "    cv2.putText(frame, badge_text, (32, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 1)\n",
    "\n",
    "    y += 40\n",
    "    cv2.putText(frame, f\"Bas Donusu (Yaw): {yaw_angle:.1f}\", (25, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (170, 170, 255), 1)\n",
    "    cv2.putText(frame, f\"Dikkat Dag.: {'EVET' if distraction_state else 'HAYIR'}\", (25, y + 22),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 200, 120), 1)\n",
    "\n",
    "    gaze_color = (0, 255, 255) if eye_gaze_distracted else (200, 200, 200)\n",
    "    gaze_text = f\"Goz Yonu: {eye_gaze_direction.upper()}\"\n",
    "    if eye_gaze_distracted:\n",
    "        gaze_text += \" [UYARI]\"\n",
    "    cv2.putText(frame, gaze_text, (25, y + 44),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, gaze_color, 1)\n",
    "\n",
    "    cv2.putText(frame, f\"Telefon: {'EVET' if phone_state else 'HAYIR'}\", (25, y + 66),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 140, 255), 1)\n",
    "\n",
    "    y += 95\n",
    "    if enroll_mode:\n",
    "        cv2.putText(frame, \"ANA SURUCU KAYDI: ALINIYOR (SABIT DUR)\", (25, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "    else:\n",
    "        if main_driver_enabled:\n",
    "            sim_txt = \"N/A\" if sim_value is None else f\"{sim_value:.3f}\"\n",
    "            cv2.putText(frame, f\"Ana surucu: AKTIF (sim={sim_txt})\", (25, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 255, 200), 1)\n",
    "            cv2.putText(frame, \"p: ana surucu guncelle   r: reset   q: cikis   t: test\", (25, y + 20),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (200, 200, 200), 1)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Ana surucu: PASIF (p ile kaydet)\", (25, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "\n",
    "    if self.debug_scores:\n",
    "        y += 50\n",
    "        cv2.putText(frame, f\"DBG mouth_open_score: {self.last_mouth_open_score:.3f}\", (25, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (200, 200, 200), 1)\n",
    "\n",
    "    cv2.rectangle(frame, (w - 110, 20), (w - 20, 46), (15, 120, 60), -1)\n",
    "    cv2.putText(frame, f\"FPS {fps:.0f}\", (w - 105, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 1)\n",
    "\n",
    "    graph_x = w - 260\n",
    "    graph_y = h - 120\n",
    "    legend_overlay = frame.copy()\n",
    "    cv2.rectangle(legend_overlay, (graph_x - 15, graph_y - 30), (graph_x + 220, graph_y + 90), (15, 15, 35), -1)\n",
    "    cv2.addWeighted(legend_overlay, 0.8, frame, 0.2, 0, frame)\n",
    "    cv2.putText(frame, \"Duygu Olasiliklari\", (graph_x - 5, graph_y - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (230, 230, 230), 1)\n",
    "\n",
    "    for i, (lbl, prob) in enumerate(zip(self.emotion_labels, probs)):\n",
    "        bar_len = int(float(prob) * 170)\n",
    "        clr = (40, 200, 120) if i == 0 else (0, 170, 255)\n",
    "        y0 = graph_y + i * 28\n",
    "        cv2.rectangle(frame, (graph_x, y0), (graph_x + bar_len, y0 + 20), clr, -1)\n",
    "        cv2.putText(frame, f\"{lbl}: {prob*100:.0f}%\", (graph_x + 5, y0 + 15),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.48, (255, 255, 255), 1)\n",
    "\n",
    "    self.draw_eye_trend_graph(frame)\n",
    "\n",
    "    if drowsy_state == \"Drowsy\":\n",
    "        alarm_overlay = frame.copy()\n",
    "        cv2.rectangle(alarm_overlay, (0, 0), (w, 70), (0, 0, 180), -1)\n",
    "        cv2.addWeighted(alarm_overlay, 0.85, frame, 0.15, 0, frame)\n",
    "        cv2.putText(frame, \"UYKU HALI ALARMI - GOZLER UZUN SUREDIR KAPALI\", (25, 45),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)\n",
    "\n",
    "    if distraction_state or eye_gaze_distracted:\n",
    "        dis_overlay = frame.copy()\n",
    "        cv2.rectangle(dis_overlay, (0, h - 70), (w, h), (0, 160, 255), -1)\n",
    "        cv2.addWeighted(dis_overlay, 0.85, frame, 0.15, 0, frame)\n",
    "\n",
    "        warning_text = \"DIKKAT DAGINIKLIGI: LUTFEN YOLA ODAKLANIN\"\n",
    "        if eye_gaze_distracted:\n",
    "            warning_text = \"GOZLERINIZI YOLA DONDURUN!\"\n",
    "\n",
    "        cv2.putText(frame, warning_text, (25, h - 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 0), 2)\n",
    "\n",
    "    if mismatch_state:\n",
    "        drv_overlay = frame.copy()\n",
    "        cv2.rectangle(drv_overlay, (0, 70), (w, 130), (0, 0, 255), -1)\n",
    "        cv2.addWeighted(drv_overlay, 0.85, frame, 0.15, 0, frame)\n",
    "        cv2.putText(frame, \"FARKLI SURUCU ALGILANDI!\", (25, 112),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "def _run(self, camera_id=0):\n",
    "    print(\"=\" * 60)\n",
    "    print(\"KONTROLLER:\")\n",
    "    print(\"  q: Cikis ve oturumu kaydet\")\n",
    "    print(\"  p: Ana surucu olarak kaydet/guncelle (4.0 sn kayit)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    cap = cv2.VideoCapture(camera_id)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"[HATA] Kamera acilamadi!\")\n",
    "        return\n",
    "\n",
    "    print(\"[OK] Sistem baslatildi, kamera hazir\")\n",
    "\n",
    "    while True:\n",
    "        self.frame_idx += 1\n",
    "        do_emotion = (self.frame_idx % self.emotion_every_n_frames == 0)\n",
    "\n",
    "        start = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"[HATA] Frame okunamadi, cikiliyor...\")\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray_eq = cv2.equalizeHist(gray)\n",
    "\n",
    "        results = self.face_mesh.process(rgb)\n",
    "\n",
    "        smooth_eye_score = 1.0\n",
    "        closed_eye_frames = self.safety_system.closed_eye_frames\n",
    "        drowsy_state = self.safety_system.state\n",
    "        head_down_score = 0.0\n",
    "        yaw_angle = 0.0\n",
    "        distraction_state = False\n",
    "        eye_gaze_distracted = False\n",
    "        eye_gaze_direction = \"center\"\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            face_landmarks = results.multi_face_landmarks[0].landmark\n",
    "            raw_eye_open_score, _ = compute_eye_openness(face_landmarks)\n",
    "            smooth_eye_score, closed_eye_frames, drowsy_state = self.safety_system.update(raw_eye_open_score)\n",
    "\n",
    "            # --- 10 saniye gÃ¶z kapalÄ± -> WEB tetikle (web hata verirse telegram fallback) ---\n",
    "            now = time.time()\n",
    "            eyes_closed = (smooth_eye_score < self.safety_system.eye_open_threshold)\n",
    "\n",
    "            if eyes_closed:\n",
    "                if self._eyes_closed_since is None:\n",
    "                    self._eyes_closed_since = now\n",
    "                closed_sec = now - self._eyes_closed_since\n",
    "\n",
    "                if (closed_sec >= EMERGENCY_EYES_CLOSED_SECONDS) and ((now - self._last_emergency_sent) >= self._emergency_cooldown):\n",
    "                    session_file = getattr(self.data_logger, \"log_file\", None)\n",
    "                    trigger_emergency_to_web_async(\n",
    "                        reason=f\"Gozler {int(EMERGENCY_EYES_CLOSED_SECONDS)} saniyedir kapali\",\n",
    "                        seconds=closed_sec,\n",
    "                        session_filename=session_file,\n",
    "                        extra={\"type\": \"eyes_closed\"}\n",
    "                    )\n",
    "                    self._last_emergency_sent = now\n",
    "            else:\n",
    "                self._eyes_closed_since = None\n",
    "\n",
    "            h_img, w_img = frame.shape[:2]\n",
    "            eye_indices = [33, 133, 159, 160, 145, 144, 263, 362, 386, 387, 374, 373]\n",
    "            for idx in eye_indices:\n",
    "                lm = face_landmarks[idx]\n",
    "                cv2.circle(frame, (int(lm.x * w_img), int(lm.y * h_img)), 1, (0, 255, 255), -1)\n",
    "\n",
    "            nose_lm = face_landmarks[1]\n",
    "            left_eye_lm = face_landmarks[33]\n",
    "            right_eye_lm = face_landmarks[263]\n",
    "            eye_center_y = (left_eye_lm.y + right_eye_lm.y) / 2.0\n",
    "            head_down_score = float(nose_lm.y - eye_center_y)\n",
    "\n",
    "            yaw_angle, pitch, roll = compute_head_pose(face_landmarks, w_img, h_img)\n",
    "            distraction_state = self.distraction_detector.update(yaw_angle)\n",
    "\n",
    "            eye_gaze_distracted, eye_gaze_direction, _ = self.eye_gaze_detector.update(face_landmarks)\n",
    "\n",
    "            if self.debug_scores:\n",
    "                iris_left = face_landmarks[468]\n",
    "                cv2.circle(frame, (int(iris_left.x * w_img), int(iris_left.y * h_img)), 2, (0, 255, 0), -1)\n",
    "                iris_right = face_landmarks[473]\n",
    "                cv2.circle(frame, (int(iris_right.x * w_img), int(iris_right.y * h_img)), 2, (0, 255, 0), -1)\n",
    "\n",
    "        faces = self.face_cascade.detectMultiScale(\n",
    "            gray_eq,\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=7,\n",
    "            minSize=(120, 120)\n",
    "        )\n",
    "\n",
    "        emotion_idx = self.last_emotion_idx\n",
    "        probs = self.last_probabilities\n",
    "        confidence = self.last_confidence\n",
    "\n",
    "        face_bbox = None\n",
    "        face_roi = None\n",
    "        mouth_open_score = self.last_mouth_open_score\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            faces_sorted = sorted(faces, key=lambda f: f[2] * f[3], reverse=True)\n",
    "            x, y, w_face, h_face = faces_sorted[0]\n",
    "            face_bbox = (x, y, w_face, h_face)\n",
    "            face_roi = frame[y:y + h_face, x:x + w_face]\n",
    "\n",
    "            try:\n",
    "                if do_emotion:\n",
    "                    gray_face = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "                    resized_face = cv2.resize(gray_face, (48, 48))\n",
    "                    normalized_face = resized_face.astype('float32') / 255.0\n",
    "                    features = self.feature_extractor.extract_features(normalized_face)\n",
    "\n",
    "                    # mouth feature: features[14] doÄŸru (mouth bloÄŸunun ilk Ã¶zelliÄŸi)\n",
    "                    mouth_open_score = float(features[14]) if features.size > 14 else 0.0\n",
    "                    self.last_mouth_open_score = mouth_open_score\n",
    "\n",
    "                    emotion_idx, probs, confidence = self.predict_emotion_from_features(\n",
    "                        features, smooth_eye_score, drowsy_state, head_down_score, mouth_open_score\n",
    "                    )\n",
    "\n",
    "                    self.last_emotion_idx = emotion_idx\n",
    "                    self.last_probabilities = probs\n",
    "                    self.last_confidence = confidence\n",
    "\n",
    "                box_color = (0, 255, 0) if emotion_idx == 0 else (255, 100, 0)\n",
    "                cv2.rectangle(frame, (x, y), (x + w_face, y + h_face), box_color, 3)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[HATA] predict_emotion: {e}\")\n",
    "        else:\n",
    "            cv2.putText(frame, \"YUZ ALGILANAMADI\", (420, 360),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)\n",
    "\n",
    "        # ENROLL MODE\n",
    "        if self.enroll_mode and face_roi is not None:\n",
    "            fg = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "            blur_score = cv2.Laplacian(fg, cv2.CV_64F).var()\n",
    "            if blur_score > self.enroll_blur_threshold:\n",
    "                self.enroll_samples.append(fg)\n",
    "\n",
    "            if (time.time() - self.enroll_start_time) >= self.enroll_duration:\n",
    "                ok = self.driver_id.enroll_multi(self.enroll_samples)\n",
    "                self.enroll_mode = False\n",
    "                if ok:\n",
    "                    self.main_driver_enabled = True\n",
    "                    self.sim_history.clear()\n",
    "                    self.driver_mismatch_frames = 0\n",
    "                    self.driver_mismatch_state = False\n",
    "                    print(\"[OK] Ana surucu profili (coklu kare) kaydedildi/guncellendi.\")\n",
    "                else:\n",
    "                    print(\"[UYARI] Ana surucu kaydi basarisiz (yeterli kaliteli kare yok).\")\n",
    "\n",
    "        # Telefon\n",
    "        phone_state, phone_info, _ = self.phone_detector.update(frame, face_bbox)\n",
    "        if phone_state:\n",
    "            self.phone_detector.draw_detections(frame, phone_info)\n",
    "            distraction_state = True\n",
    "\n",
    "        if eye_gaze_distracted:\n",
    "            distraction_state = True\n",
    "\n",
    "        # ANA SÃœRÃœCÃœ TANIMA\n",
    "        driver_mismatch = False\n",
    "        if self.main_driver_enabled and face_roi is not None and (not self.enroll_mode):\n",
    "            try:\n",
    "                fg = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)\n",
    "                blur_score = cv2.Laplacian(fg, cv2.CV_64F).var()\n",
    "                if blur_score > self.match_blur_threshold:\n",
    "                    sim = self.driver_id.similarity(fg)\n",
    "                    if sim is not None:\n",
    "                        self.sim_history.append(sim)\n",
    "\n",
    "                sim_smooth = float(np.mean(self.sim_history)) if len(self.sim_history) else None\n",
    "                self.last_driver_similarity = sim_smooth\n",
    "\n",
    "                if sim_smooth is not None:\n",
    "                    if not self.driver_mismatch_state:\n",
    "                        if sim_smooth < self.sim_low_threshold:\n",
    "                            self.driver_mismatch_frames += 1\n",
    "                        else:\n",
    "                            self.driver_mismatch_frames = max(0, self.driver_mismatch_frames - 5)\n",
    "\n",
    "                        if self.driver_mismatch_frames >= self.driver_mismatch_threshold_frames:\n",
    "                            self.driver_mismatch_state = True\n",
    "                    else:\n",
    "                        if sim_smooth > self.sim_high_threshold:\n",
    "                            self.driver_mismatch_frames = max(0, self.driver_mismatch_frames - 6)\n",
    "                        else:\n",
    "                            self.driver_mismatch_frames += 1\n",
    "\n",
    "                        if self.driver_mismatch_frames <= 5:\n",
    "                            self.driver_mismatch_state = False\n",
    "\n",
    "                driver_mismatch = self.driver_mismatch_state\n",
    "\n",
    "                now = time.time()\n",
    "                if driver_mismatch and (now - self.last_driver_alert_time > self.driver_alert_cooldown):\n",
    "                    if self.audio_system:\n",
    "                        self.audio_system.play_alert(\"distraction\")\n",
    "                    self.last_driver_alert_time = now\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[HATA] driver identify: {e}\")\n",
    "\n",
    "        self.eye_score_history.append(smooth_eye_score)\n",
    "\n",
    "        if self.audio_system:\n",
    "            if drowsy_state == \"Drowsy\":\n",
    "                self.audio_system.play_alert(\"drowsy\")\n",
    "            elif distraction_state:\n",
    "                self.audio_system.play_alert(\"distraction\")\n",
    "\n",
    "        self.data_logger.add_record(\n",
    "            emotion_idx, self.emotion_labels, probs,\n",
    "            smooth_eye_score, drowsy_state, yaw_angle,\n",
    "            distraction_state, phone_state,\n",
    "            self.last_driver_similarity, driver_mismatch,\n",
    "            mouth_open_score=mouth_open_score,\n",
    "            eye_gaze_distracted=eye_gaze_distracted,\n",
    "            eye_gaze_direction=eye_gaze_direction\n",
    "        )\n",
    "\n",
    "        fps = 1.0 / max(time.time() - start, 1e-6)\n",
    "        self.fps_buffer.append(fps)\n",
    "        avg_fps = float(np.mean(self.fps_buffer))\n",
    "\n",
    "        self.draw_overlay(\n",
    "            frame, emotion_idx, probs, confidence,\n",
    "            smooth_eye_score, closed_eye_frames, drowsy_state,\n",
    "            avg_fps, yaw_angle, distraction_state, phone_state,\n",
    "            self.last_driver_similarity, self.main_driver_enabled,\n",
    "            driver_mismatch, self.enroll_mode,\n",
    "            eye_gaze_distracted, eye_gaze_direction\n",
    "        )\n",
    "\n",
    "        cv2.imshow(\"Tam Surucu Izleme Sistemi\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"q\"):\n",
    "            print(\"\\n[INFO] Cikis yapiliyor...\")\n",
    "            break\n",
    "        elif key == ord(\"r\"):\n",
    "            print(\"\\n[INFO] Istatistikler sifirlandi\")\n",
    "            self.phone_detector.reset_statistics()\n",
    "            self.sim_history.clear()\n",
    "            self.driver_mismatch_frames = 0\n",
    "            self.driver_mismatch_state = False\n",
    "        elif key == ord(\"p\"):\n",
    "            if face_roi is None:\n",
    "                print(\"[UYARI] p: Yuz bulunamadi, ana surucu kaydedilemedi.\")\n",
    "            else:\n",
    "                self.enroll_mode = True\n",
    "                self.enroll_samples = []\n",
    "                self.enroll_start_time = time.time()\n",
    "                print(\"[INFO] Ana surucu kaydi basladi... (4.0 sn sabit dur)\")\n",
    "        elif key == ord(\"t\"):\n",
    "            session_file = getattr(self.data_logger, \"log_file\", None)\n",
    "            print(\"[TEST] Manuel emergency tetikleniyor -> WEB (fallback telegram aktif)\")\n",
    "            trigger_emergency_to_web_async(\n",
    "                reason=\"MANUEL TEST (driver icinden)\",\n",
    "                seconds=0.0,\n",
    "                session_filename=session_file,\n",
    "                extra={\"type\": \"manual_test\"}\n",
    "            )\n",
    "\n",
    "    print(\"\\n[INFO] Oturum kaydediliyor...\")\n",
    "    self.data_logger.save_session()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    self.face_mesh.close()\n",
    "    print(\"[OK] Sistem kapatildi\")\n",
    "\n",
    "# MetodlarÄ± sÄ±nÄ±fa baÄŸla\n",
    "FullDriverMonitoringSystem.draw_overlay = _draw_overlay\n",
    "FullDriverMonitoringSystem.run = _run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c70236f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook'tan baÅŸlatma\n",
    "\n",
    "def baslat_sistemi_konsoldan():\n",
    "    system = FullDriverMonitoringSystem(\n",
    "        model_path=\"emotion_model.pkl\",\n",
    "        norm_path=\"normalization_params.npz\"\n",
    "    )\n",
    "    system.run(camera_id=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "644198a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Tam Surucu Izleme Sistemi\n",
      "============================================================\n",
      "[OK] Duygu modeli yuklendi\n",
      "[OK] Goz yonu tespit sistemi hazir\n",
      "[INFO] YOLOv5 modeli yukleniyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gts_-/.cache\\torch\\hub\\ultralytics_yolov5_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UYARI] YOLOv5 yuklenemedi: No module named 'ultralytics'\n",
      "[INFO] Sadece el-tabanlÄ± tespit kullanilacak\n",
      "[OK] MediaPipe Hands yuklendi\n",
      "[OK] Telefon tespit sistemi hazir\n",
      "[OK] Ses sistemi baslatildi\n",
      "[OK] Veri kayit sistemi hazir\n",
      "[OK] Ana sÃ¼rÃ¼cÃ¼ profili yÃ¼klendi: driver_profile.npy\n",
      "============================================================\n",
      "KONTROLLER:\n",
      "  q: Cikis ve oturumu kaydet\n",
      "  p: Ana surucu olarak kaydet/guncelle (4.0 sn kayit)\n",
      "============================================================\n",
      "[OK] Sistem baslatildi, kamera hazir\n",
      "\n",
      "[INFO] Cikis yapiliyor...\n",
      "\n",
      "[INFO] Oturum kaydediliyor...\n",
      "\n",
      "[LOG] Oturum kaydedildi: sessions\\surucu_oturumu_20251223_210858.json\n",
      "[LOG] SÃ¼re: 3 saniye\n",
      "[OK] Sistem kapatildi\n"
     ]
    }
   ],
   "source": [
    "baslat_sistemi_konsoldan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4094b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37642ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gorsel)",
   "language": "python",
   "name": "gorsel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
